Saturday, July 5, 2008 - Mikio@home

Matrix

The biggest issue is the following: BLAS allows some pretty special
optimizations. For example, you can multiply with the transpose of a
matrix, or with a submatrix. On the other hand, since addition is
organized in terms of vectors, you cannot add the transpose of a
matrix to another matrix, or add to a submatrix. Likewise, one can
operate on rows and columns of matrices (and submatrices), but for
example, not treat these as matrices and transpose them.

So, the problem is that we cannot implement these operations in a
fashion which is easy to grasp. We cannot construct such objects
because most operations won't be defined for those... .

Actually, I think there are (at least) the following alternatives:

  * Make sure that operations which are not directly supported by BLAS
    are not performed. This can be achieved either by throwing
    exceptions whenever the operation cannot be performed, or making
    submatrices and subvectors special classes which do not come with
    a full set of operations. This usually means that you have to
    introduce a "dup" or "compact" somewhere. Actually, this is quite
    ugly, because nobody will be able to remember when to use the
    compact and when not. Finding the right position by trial and
    error is not an option.

  * Add further special versions of the methods like "tmul" (object is
    transposed), and "tmult" (both sides are transposed). Of course,
    this leads to an exponential growth of methods. Maybe it is better
    to add an optional argument, trans, such that x.mul(y, "TN")
    transposes x, but not y.

  * Do nothing about those special cases. Have "power users" use GEMV
    and so on. This means, however that if you want to use those
    features you have to use a significantly different API from the
    one you use elsewhere.

  * Make sure that all the methods also work for the submatrices. This
    would mean to add a lot of code to handle all the special cases
    gracefully. The problem is that it becomes quite unclear when
    exactly BLAS can handle a case efficiently, thereby making the
    whole process much less transparent.

Okay, so according to our rules that we try to model the features of
BLAS as faithfully as possible, and that easy stuff should be easy,
but you should be able to do it in a more advanced fashion if you have
to, we get the following assessment:

  * Prohibiting the operations in an otherwise generic framework
    is impractical.

  * Adding further operations might be possible, but use the
    parameterized version (not an exponential multitude of
    methods). This makes such calls quite ugly nevertheless... .

  * Just using GEMV should be the LAST line of defense.

  * Extending to the case where everything is possible is maybe too
    much for starters.

So let's try the second version... .

Tried it, it's ugly. The nice thing about doing things like

   X.transpose().mul(A)

is that you really only have to add the information you are interested
in. In particular, when you want do things like
   
   X.submatrix(3, 3, 5, 5).mul(A, C)

Then you don't really want to supply the original arguments for A... .

On the other hand, in BLAS only the minimal amount of information is
required. For example, the sizes of the problem are usually given only
once and then, you only pass the "leading dimension", that is, the
skip from matrix to matrix... .

Hm... . Okay, maybe it is really about leaving that submatrix stuff
out for later... . And maybe also the in-place stuff... . This means
that we will generate many many temporary objects. But on the other
hand, this might allow to settle on the basic operations first, and
later add features to make it more performant.

Class methods
=============

Construction

	DoubleMatrix(rows, columns)  fills with zeros
	DoubleMatrix(rows, columns, double... data)
	DoubleMatrix(double[][])
	DoubleMatrix(double[])
	DoubleMatrix(d)

	zeros(rows, columns)
	ones(rows, columns)
	diag(m)
	eye(size)

Object methods
==============
  
 m - matrix
 d - double
 i,j,c,r - integer

General operations

	m.columns()	    number of columns
	m.rows()            number of rows
	m.length()	    length (columns * rows)
	m.resize(r, c)      resizes, discard everything
	m.reshape(r, c)     number of elements must stay the same
	m1.copy(m2)	    copies contents of m1 to m2
	m.transpose()	    transposes m
	m.dup()		    return copy of m
	m.isRowVector()	    when columns == 1
	m.isColumnVector()  when rows == 1
	m.isVector()        when either of the above
	m.isMatrix()	    when not isMatrix()
	m.isScalar()	    when columns == 1 and rows == 1

Access

	m.index(i, j)	return index of element at row i, column j
	m.get(i,j)	m[i,j]
	m.put(i,j, d)	m[i,j] = d
	m.getRow(i)     returns (copy) of row
	m.getColumn(i)  returns (copy) of column
	m.putRow(i, m)  
	m.putColumn(i, m)
	m.getSlice(id1, id2)        More expensive, can get you anything
	m.putSlice(id1, id2, m)
	m.diag()	get diagonal
	m.getData()	returns double[]

Arithmetics

   For addition (each function returns result)

	m1.add(m2)     m1 + m2
	m1.add(d)      m1 + d (on each entry)
	m1.addi(m2, m3)  m3 = m1 + m2 (if m3 omitted, m3 == m1)
	m1.addi(m2)    m1 = m1 + m2

    For subtraction

	as above, and also

	m1.rsub(m2)       m2 - m1 ("reversed subtraction")
	m1.rsub(d)        d - m1 (on each entry)

	(not necessary for the fully qualified version)

    For multiplication

        as for addition (however note that in-place is in general
	only possible if both matrices are square), and also
	
	m1.emul(m2)	 m1 .* m2
	m1.emuli(m2, m3)

    For division

	as for subtraction, always means "elementwise"

    Of course

        m.rankOneUpdate(x, y)

Logical Operations

    Less than
	
	m1.lt(m2)	m1 < m2 (elementwise)
	m1.lt(d)	m1 < d (on each entry)
	m1.lti(m2, m3)
	m1.lti(m2)

    Same for: greater than (gt, ">"),
	less than or equal (le, "<="),
	greater than or qual (ge, ">=")
	equal (eq, "==")
	not equal (ne, "!=")
	or (or, "|") (double values first mapped to 0 and 1)
	and (and, "&") ( - " - )
	xor (xor, "^") ( - " - )

    Not
	m1.not()	!m1

Functions

	m.sin()		sin(m) (elementwise)
	m.sini()

    Same for: cos, tan, sinh, cosh, log, log10, exp, exp10, ...

        m.power(d)	m**d (elementwise)

Scalar products and norms
	
	m1.dot(m2)	<m1,m2> (elementwise, irrespective of other dimensions)

----------------------------------------------------------------------
Thursday, February 21, 2008 - near Feuerbach station, Friedenau

RULE 0: does it integrate nicely with blas?
RULE 1: layered approach such that you can ALWAYS directly access the 
	lowest layer (only assembler might be faster!)

[mikio] rewrite python script in ruby, directly produce jni .c and 
  .java files (-> just use javah)
[schabby] rename packages -> edu.ida.la
  FloatMatrix, DoubleMatrix
  ComplexFloatMatrix, ComplexDoubleMatrix

  rows()
  columns()
  set(row, col, val)
  get(row, col)
  getAsArray()
  vec = getRow(row); array = getRowAsArray()
  vec = getCol(col); array = ...
  setRow(row, vec); setRow(row, array)
  setCol(col, vec); setCol(row, array)
  mat.getSubmatrix(rowindices, colindices)
  vec.getSubvector(indices)

operation with copy
  mat = mat.mul(matrix) 
  mat = mat.add(matrix)
  mat = mat.sub(matrix)
  vec = mat.mul(vec)
  vec = vec.mul(mat)
  mat = mat.transpose()  
  
  mat = mat.mulEl(matrix)

inplace operations
  resultmatrix = mat.mul(matrix, resultmatrix)
  resultmatrix = mat.add(matrix, resultmatrix)
  ...

for the die-hards
  //compute y = alpha * A * x + beta * y
  gemv(alpha, A, transpose?, x, beta, y)

for the uncurably die-hards
  just use BlasLevel1 ...
    
Lapack (matrix inversion/solving linear equations, eigenvalues/vectors) 
  as class with static functions
elementwise functions (sin, cos, log, exp, ...) mat.sin(), 
  and sin(matrix) { return m.sin(); }


Prio 2 Features:
  lazy copying of transpose
  BLAS supporting "views" of matrices
  write/read to some standard file format (XML, CSV, raw)

Prio n-1 Features:
  n-dim tensors
  sparse matrices 

Prio n -> oo Features:
  Defeat Vector3d, Vector3f etc.
  matrices stored on disc
  matrix multiplication on a grid
  matrices computed by a function, with caches (-> kernel matrices)
  solvers for linear and quadratic programming


open:
   where to host? (TU, google, sourceforge, java.net)



